#Imports.
from execute_commands import *
from numpy import unique
import sys
from tqdm import tqdm
import os 
import warnings
from pandas import read_csv
import json
from sanity_checks import check_ids, check_dates, check_ip, check_port, check_AET
from datetime import datetime
from typing import Iterator
from convert import convert_all

warnings.filterwarnings("ignore")

#Default paths to get the patient ids 
dump_path = "../files/query_patient_ids.dcm"
dump_txt_path = "../files/dump.txt"

########################################################################################################################
########################################################FUNCTIONS#######################################################
########################################################################################################################

def modify_query_parameters(
	server_ip : str = "88.202.185.144",
	port : int = 104,
	dump_path_ : str = dump_path,
	dump_txt_path_ : str = dump_txt_path,
	aec : str = "theServerAET") -> tuple:
	"""
	Modifies the command paramaters such as the dicom server ip, port number and the path to dump the results of the find. 
	Args : 
		server_ip (string) : server ip
		port (int) : port 
		dump_path_ (string) : path to where the generated .dcm file will be from dump2dcm command. 
		dump_txt_path_ (string) : path to where the text file from which the .dcm file will be generated.
		aec (string) : server_AET
	Returns : 
		tuple of strings : modified commands using input parameters.
	"""
	dump_query = "dump2dcm "+ dump_txt_path_+ " " + dump_path_
	scrape_patients_query = 'findscu '+ server_ip +' '+ str(port) +' -k 0010,0020={} --key 0008,0020={} --key 0008,0030 -aec '+ aec +' --patient ' + dump_path
	
	dump_query = dump_query.replace(
		dump_txt_path, dump_txt_path_).replace(
		dump_path, dump_path_)

	scrape_patients_query = scrape_patients_query.replace(
		"88.202.185.144", server_ip).replace(
		" 104", " "+str(port)).replace(
		dump_path, dump_path_).replace(
		"theServerAET", aec)

	return dump_query, scrape_patients_query

def get_and_store_patients(
	patient_ids : list,
	dates : list,
	text_file : str = "../files/patients.txt",
	server_ip : str = "88.202.185.144",
	port : int = 104,
	dump_path_ : str = dump_path,
	dump_txt_path_ : str = dump_txt_path,
	aec : str = "theServerAET"):
	"""
	Queries for patient ids passed as an argument and saves the resulting logs in a text file.
	Args : 
		patient_ids (list) : list of patient ids to be queried.
		dates (list) : list of study dates.
		text_file (string) : path to text file containing the logs generated by modify_query_parameters function.
		server_ip (string) : server ip.
		port (int) : port.
		dump_path_ (string) : path to where the generated .dcm file will be from dump2dcm command. 
		dump_txt_path_ (string) : path to where the text file from which the .dcm file will be generated.
		aec (string) : server_AET
	"""

	check_ip(server_ip)
	check_port(port)
	check_AET(aec , server = True)

	#delete patients text file if already exists.
	if os.path.isfile(text_file) : 
		os.remove(text_file)

	dump_query , scrape_patients_query = modify_query_parameters(server_ip, port, dump_path_, dump_txt_path_, aec)
	
	res = run(dump_query)

	for i, id_ in enumerate(patient_ids) : 
		
		check_ids(str(id_))
		res = run(scrape_patients_query.format(str(id_), dates[i]))
		write_file(res, file = text_file)

def readLineByLine(filename : str) -> Iterator[str]:
	"""
	Returns a list of lines of textfile located at path filename.
	Args : 
		filename (string) : path to textfile to be read.
	Returns : 
		Iterator : list of text lines in file.
	"""
	with open(filename, 'r', encoding = "utf8") as f:
		for line in f:   
			yield line.strip('\n')

def process_text_files(filename : str, target_id : str = "PATIENT") -> list:
	"""
	Gives list of patient ids, study instance UID or series instance UID
	Args : 
		filename (string) : path to textfile to be read.
		target_id (string) : a key to decide which list of ids will be returned. 
		("PATIENT" --> patient ids, "STUDY" --> study instance UID, "SERIES" --> series instance UID)
	Returns : 
		list : list of unique ids.
	"""
	tag_to_id = {
	"PATIENT" : "(0010,0020)",
	"STUDY" : "(0020,000d)",
	"STUDY_DATE" : "(0008,0020)", 
	"STUDY_TIME" : "(0008,0030)",
	"SERIES" : "(0020,000e)"}

	id_table = []
    
    #Iterate over text lines
	for line in readLineByLine(filename):
		#if current line contains a given tag then extract information from it.
		if tag_to_id[target_id] in line:
			
			id_ = ""
			try : 
				id_ = line.split(" ")[3]

			#In case line.split gives a list of length less that 4 pass to next line.
			except IndexError : pass

			id_ = id_.replace("[","").replace("]","")

			if id_ == "(no" : continue
			id_table.append(id_)
	
	return list(id_table)


def parse_date(date : str) -> str : 
	"""
	Transforms a date passed as an argument to a date in format YYYYMMDD exaacly like the VR DA.
	Args : 
		date (string) : date in format dd/mm/yy (yy : two last digits of year)
	Returns : 
		list : parsed dates.
	"""

	check_dates(date)
	addition = "20"
	splitted = date.split("/")
	if int(splitted[2]) > datetime.now().year %100 : 
		addition = "19"

	if len(splitted[0]) == 1 : splitted[0] = "0" + splitted[0]
	if len(splitted[1]) == 1 : splitted[1] = "0" + splitted[1]
	
	return addition + splitted[2] + splitted[1] + splitted[0]

def process_date(date : str) -> str : 
	"""
	Process a date according to its format (a simple date or a date range)
	Args : 
		date (string) : date or date range in format dd/mm/yy or dd/mm/yy-dd/mm/yy
	Returns : processed date/date range.
	"""

	#Case a date range was passed
	if len(date.split("-")) == 2 :
		dates = date.split("-")
		dates = [parse_date(dat) for dat in dates]
		return dates[0]+"-"+dates[1]
	#Case of a single date (not a date range)
	elif len(date.split("-")) == 1 :
		return parse_date(date) 
	#Otherwise raise an error.
	else : 
		raise ValueError("Invalid date input!")

########################################################################################################################
##########################################################MAIN##########################################################
########################################################################################################################

def main(argv) : 
	
	#Reading config file.
	with open('../files/config.json') as f:
		parameters = json.load(f)


	pacs_server = parameters["server_ip"] 
	port = int(parameters["port"])
	called_aet = parameters["AET"] 
	calling_aet = parameters["server_AET"]
	output_dir = parameters["directory"]

	#TODO replace this by full flexible safe parsing

	table = read_csv("../files/"+argv[0])
	cols= table.columns
	target_ids = list(table[cols[0]])
	
	dates = list(table[cols[1]])
	dates = [process_date(date) for date in dates]

	#echo
	echo_res = echo(called_aet, server_ip = pacs_server, server_AET = calling_aet, port = port)

	
	#Getting all patient ids.
	get_and_store_patients(target_ids , dates, server_ip = pacs_server, port = port, aec = calling_aet)
	ids_ = process_text_files("../files/patients.txt")
	
	print("Retrieving images...")
	
	#Loop over all patient ids. 
	k = -1
	for patient_id in tqdm(ids_) : 
		k+=1
		patient_dir = os.path.join(output_dir, "sub-"+ patient_id)

		#Store all later retrieved files of current patient within the patient_id directory.
		if not os.path.isdir(patient_dir):
			os.mkdir(patient_dir)

		#Look for studies of current patient.
		find_study_res = find_study(
			called_aet,
			dates[k],
			server_ip = pacs_server,
			server_AET = calling_aet,
			port = port,
			PATIENTID = patient_id)
		
		#Generate study_reponses text of current patient.
		study_txt = os.path.join(patient_dir,'study_responses.txt')
		
		if os.path.isfile(study_txt) : 
			os.remove(study_txt)
		
		write_file(find_study_res, file = study_txt)
		
		#Extract all study ids.
		study_ids = process_text_files(study_txt, target_id = "STUDY")
		study_dates = process_text_files(study_txt, target_id = "STUDY_DATE")
		study_times = process_text_files(study_txt, target_id = "STUDY_TIME")

		study_dates = study_dates[1:]

		#Basic sanity checks... 
		assert len(study_dates) == len(study_ids)
		assert len(study_times) == len(study_ids)

		#loop over studies.
		for i, study in enumerate(study_ids) : 

			patient_study_output_dir = os.path.join(patient_dir, "ses-" + study_dates[i] + study_times[i])

			#Store all later retrieved files of current study within the study_id directory.
			if not os.path.isdir(patient_study_output_dir):
				os.mkdir(patient_study_output_dir)
			
			
			#Generate response_series text of current study.
			serie_txt = os.path.join(patient_study_output_dir,"response_series.txt")

			if os.path.isfile(serie_txt) : 
				os.remove(serie_txt)

			#Look for series of current patient and current study.
			find_series_res = find_series(
				called_aet,
				dates[k],
				server_ip = pacs_server,
				server_AET = calling_aet,
				port = port,
				PATIENTID = patient_id,
				STUDYUID = study)
			
			write_file(find_series_res, file = serie_txt)

			#Extract all series ids.
			series_ids = process_text_files(serie_txt, target_id = "SERIES")
			
			#loop over series
			for serie_id in series_ids :
				patient_serie_output_dir = os.path.join(patient_study_output_dir ,serie_id)

				#Store all later retrieved files of current patient within the serie_id directory.
				if not os.path.isdir(patient_serie_output_dir):
					os.mkdir(patient_serie_output_dir)
				
				#Retrieving files of current patient, study and serie.
				get_res = get(
					called_aet,
					dates[k],
					['0008,0060="MR"', '0010,0020=""'],
					server_ip = pacs_server,
					server_AET = calling_aet,
					port = port,
					PATIENTID = patient_id,
					STUDYINSTANCEUID = study,
					SERIESINSTANCEUID = serie_id,
					OUTDIR  = patient_serie_output_dir)

	

if __name__ == "__main__" : 
	main(sys.argv[1:])